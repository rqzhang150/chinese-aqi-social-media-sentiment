---
title: "Exploratory Weiboscope Data Analysis"
author: "Ruoqi Zhang"
date: "4/4/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, cache=TRUE)
library(sf)
library(tidyverse)
library(readr)
library(gt)
```

# Weibo (微博) and Open WeiboScope Dataset

## About Weibo
Weibo (微博), widely dubbed as China's version of Twitter, is a social networking platform provided by Sina, now a subsidiary of Alibaba Group, one of the largest Internet firms in mainland China. 

Due to online censorship, Chinese Internet users are unable to access many sites that do not conform to government censorship requests or otherwise deemed sensitive. Those sites include widely used services including Twitter, Google, Facebook, Instagram, and Snapchat. Partially as a result of Chinese Internet users' limited access to foreign services, Weibo boasts a Monthly Active User based over 400 million and is widely regarded as one of the important barometer of China's public sentiment on social issues.

## About Open WeiboScope

The most important dataset in this project is the Open Weibo Scope dataset published by a team at Hong Kong University led by King-wa Fu. The project scraped Weibo posts and their matadata published by users with more than 1,000 followers since January 2011. 

The research team published its 2012 dataset that contains over 200 million Weibo posts that fit the previous criteria. In the dataset, each week's data is published separately. In this step of the project, we examin the WeiboScope data in Week 1, 2012.

**Because of the size of the data, the csv file is not uploaded to Github. It can be downloaded at [Weibo Scope's Data Portal](https://hub.hku.hk/cris/dataset/dataset107483)**

```{r data_import, echo=FALSE}
## Importing Week 1 WeiboScope data and specifies the types of the columns.
week1 <- read_csv("week1.csv",
                  col_types = cols(mid = col_character(),
                                   retweeted_status_mid = col_character(),
                                   uid = col_character(),
                                   retweeted_uid = col_character(),
                                   source = col_character(),
                                   image = col_logical(),
                                   text = col_character(),
                                   geo = col_character(),
                                   created_at = col_datetime(format = ""),
                                   deleted_last_seen = col_character(),
                                   permission_denied = col_character()))

```

## WeiboScope Data Structure

Metadata includes such as user's anonymous id (`uid`), the platform used to publish the post (`source`),  whether the post contains image(s) (`image`), original text of the post (`text`), geospatial coordinate of the post (`geo`), and time of creation of the post (`created_at`).

Additionally, as Weibo is required to conform with government's censorship requirements in sensitive issues. This dataset also tracks whether the post is deleted. Weibo displays posts that are censored in different ways: either saying that it's deleted (`deleted_last_seen`) or the user does not have permission to view the post (`permission_denied`).

Here's what a regular WeiboScope entry look like:

```{r sample_entry}
week1 %>% 
  filter(!is.na(permission_denied) | !is.na(deleted_last_seen)) %>% # We want to make sure that the fields are not NA
  slice(10) %>% 
  gt()
# 
# week2 %>% 
#   filter(!is.na(geo)) %>% 
#   count(source) %>% 
#   arrange(desc(n))
# 
# week2 %>% 
#   filter(str_detect(text, "环保"))
# 
# week1 %>% 
#   filter(str_detect(text, "PM2.5"))

```

## Post Creation Time Variation

Using a graph by ggplot, we explore the time distribution presented by the Week 1 data.

```{r summary_graph}
## In this plot, 
week1 %>% 
  mutate(is_geo = !is.na(geo)) %>% 
  ggplot(aes(x = created_at)) +
    geom_freqpoly(binwidth = 600) +
    theme_minimal() +
    labs(x = NULL,
         y = "Number of Posts Per Minute",
         title = paste("Variations In Number of Weibo Posts Across A Week"),
         subtitle = paste("Number of Weibo posts between", (week1 %>% arrange(created_at) %>% slice(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")), "and", (week1 %>% arrange(desc(created_at)) %>% slice(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")),"."),
         caption = "HKU WeiboScope Data: King-wa Fu, CH Chan, Michael Chau. Assessing Censorship \non Microblogs in China: Discriminatory Keyword Analysis and Impact Evaluation of the 'Real Name Registration' Policy.\nIEEE Internet Computing. 2013; 17(3): 42-50. http://doi.ieeecomputersociety.org/10.1109/MIC.2013.28")

```

# Future Plans

In the future, for this dataset, I would like to aggregate data in all 54 weeks in 2012, and plot out the geographic distribution of Weibo posts in China.
