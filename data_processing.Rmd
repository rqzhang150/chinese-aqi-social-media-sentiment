---
title: "Data Processing"
author: "Ruoqi Zhang"
output:
  html_document:
    df_print: paged
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(cache=TRUE)
library(sf)
library(tidyverse)
library(gt)
library(sparklyr)
library(tictoc)
library(lubridate)
```

```{r sparklyr_setup, include=TRUE}

# Set environment variable for JDK 1.8 in order to point sparklyr package to the
# correct directory.

Sys.setenv(JAVA_HOME = "/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home")

# Configuring Sparklyr settings.

conf <- list()

# Assign 4 CPU cores, 10G memory to process the data.

conf$`sparklyr.cores.local` <- 4
conf$`sparklyr.shell.driver-memory` <- "10G"
conf$spark.memory.fraction <- 0.9

# Connect to local Spark instance.

sc <- spark_connect(master = "local",
                    config = conf)

```


# Time Distribution in Week 1

```{r data_proc}

# Time the loading time for the csv files.

tic("sparkload")

# Read all WeiboScope csv files to WEIBOSCOPE_ALL variable through spark. The
# reason that we use Spark is that the files are too big to be stored in memory.
# Thus, we need a distributional computation platfrom to properly produce
# analysis on tis dataset. We process the dataset using spark, and generate
# dataframes that contains manageable metadata, and visualize it using ggplot.

WEIBOSCOPE_ALL <- spark_read_csv(sc,
  name = "weiboscope", 
  
  # Weiboscope data is stored under datasets/weiboscope_data in .csv formats.
  # Using wildcard, we read in all the data in that directory. Because
  # Weiboscope data already contains timestamp of the posts, we do not worry
  # about the filename.
  
  path = "datasets/weiboscope_data/*.csv",
  
  # Specifying the column types manually without letting Spark infering the
  # column types. The following column types are not specified under R coltypes,
  # but instead uses Spark SQL format.
  
  infer_schema = FALSE,
  columns = list(
    mid = "character",
    retweeted_status_mid = "character",
    uid = "character",
    retweeted_uid = "character",
    source = "character",
    image = "integer",
    text = "character",
    geo = "character",
    created_at = "timestamp",
    deleted_last_seen = "timestamp",
    permission_denied = "timestamp"
  )
)
toc()

```

```{r creation_time_dist}

tic("creation_time_dist")
creation_time_dist <- WEIBOSCOPE_ALL %>% 
  mutate(created_date = to_date(created_at)) %>% 
  group_by(created_date) %>% 
  summarize(post_created = n()) %>% 
  collect()
toc()

write_rds(creation_time_dist, "weibo_air_quality/data/creation_time_dist.rds")

ggplot(data = num_created_date, aes(x = created_date, y = post_created)) +
  geom_line()

```


```{r time_distribution_rds}

# 


week1 %>% 
  ggplot(aes(x = created_at)) +
    geom_freqpoly(binwidth = 600)

week1 %>% 
  mutate(created_at = ymd_hms(created_at))

week1 %>% 
  mutate(week_day = day(created_at))

week1 %>% 
  

tic("week1_spark_graph")
week1 %>% 
  ggplot(aes(x = created_at)) +
    geom_freqpoly(binwidth = 600) +
    theme_minimal() +
    labs(x = NULL,
         y = "Number of Posts Per Minute",
         title = paste("Variations In Number of Weibo Posts Across A Week"),
         subtitle = paste("Number of Weibo posts between", (week1 %>% arrange(created_at) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")), "and", (week1 %>% arrange(desc(created_at)) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")),"."),
         caption = "HKU WeiboScope Data: King-wa Fu, CH Chan, Michael Chau. Assessing Censorship \non Microblogs in China: Discriminatory Keyword Analysis and Impact Evaluation of the 'Real Name Registration' Policy.\nIEEE Internet Computing. 2013; 17(3): 42-50. http://doi.ieeecomputersociety.org/10.1109/MIC.2013.28")
toc()


tic("week1_graph")
week1_csv %>% 
  ggplot(aes(x = created_at)) +
    geom_freqpoly(binwidth = 600) +
    theme_minimal() +
    labs(x = NULL,
         y = "Number of Posts Per Minute",
         title = paste("Variations In Number of Weibo Posts Across A Week"),
         subtitle = paste("Number of Weibo posts between", (week1 %>% arrange(created_at) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")), "and", (week1 %>% arrange(desc(created_at)) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")),"."),
         caption = "HKU WeiboScope Data: King-wa Fu, CH Chan, Michael Chau. Assessing Censorship \non Microblogs in China: Discriminatory Keyword Analysis and Impact Evaluation of the 'Real Name Registration' Policy.\nIEEE Internet Computing. 2013; 17(3): 42-50. http://doi.ieeecomputersociety.org/10.1109/MIC.2013.28")
toc()

```

