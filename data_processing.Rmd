---
title: "Data Processing"
author: "Ruoqi Zhang"
output:
  html_document:
    df_print: paged
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(cache=TRUE)
library(sf)
library(tidyverse)
library(gt)
library(sparklyr)
library(tictoc)
library(lubridate)
library(mapview)

# devtools::install_github("harryprince/geospark")

library(geospark)
library(stringr)
library(gganimate)
```

```{r sparklyr_setup, include=TRUE}

# Set environment variable for JDK 1.8 in order to point sparklyr package to the
# correct directory.

Sys.setenv(JAVA_HOME = "/Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home")

# Configuring Sparklyr settings.

conf <- list()

# Assign 4 CPU cores, 10G memory to process the data.

conf$`sparklyr.cores.local` <- 4
conf$`sparklyr.shell.driver-memory` <- "10G"
conf$spark.memory.fraction <- 0.9

conf$spark.serializer <- "org.apache.spark.serializer.KryoSerializer"
conf$spark.kryo.registrator <- "org.datasyslab.geospark.serde.GeoSparkKryoRegistrator"

# Connect to local Spark instance.

sc <- spark_connect(master = "local",
                    config = conf)

register_gis(sc)

```

# Time Distribution in Week 1

```{r data_proc}

# Time the loading time for the csv files.

tic("sparkload")

# Read all WeiboScope csv files to WEIBOSCOPE_ALL variable through spark. The
# reason that we use Spark is that the files are too big to be stored in memory.
# Thus, we need a distributional computation platfrom to properly produce
# analysis on tis dataset. We process the dataset using spark, and generate
# dataframes that contains manageable metadata, and visualize it using ggplot.

WEIBOSCOPE_ALL <- spark_read_csv(sc,
  name = "weiboscope", 
  
  # Weiboscope data is stored under datasets/weiboscope_data in .csv formats.
  # Using wildcard, we read in all the data in that directory. Because
  # Weiboscope data already contains timestamp of the posts, we do not worry
  # about the filename.
  
  path = "datasets/weiboscope_data/*.csv",
  
  # Specifying the column types manually without letting Spark infering the
  # column types. The following column types are not specified under R coltypes,
  # but instead uses Spark SQL format.
  
  infer_schema = FALSE,
  columns = list(
    mid = "character",
    retweeted_status_mid = "character",
    uid = "character",
    retweeted_uid = "character",
    source = "character",
    image = "integer",
    text = "character",
    geo = "character",
    created_at = "timestamp",
    deleted_last_seen = "timestamp",
    permission_denied = "boolean"
  )
)
toc()

week1 <- read_csv("datasets/weiboscope_data/week1.csv",
         col_types = cols(
  mid = col_character(),
  retweeted_status_mid = col_character(),
  uid = col_character(),
  retweeted_uid = col_character(),
  source = col_character(),
  image = col_character(),
  text = col_character(),
  geo = col_character(),
  created_at = col_datetime(format = ""),
  deleted_last_seen = col_datetime(format = ""),
  permission_denied = col_logical()
))

```

```{r creation_time_dist}

tic("creation_time_dist")
creation_time_dist <- WEIBOSCOPE_ALL %>% 
  mutate(created_date = to_date(created_at)) %>% 
  group_by(created_date) %>% 
  summarize(post_created = n()) %>% 
  collect()
toc()

write_rds(creation_time_dist, "weibo_air_quality/data/creation_time_dist.rds")
```

```{r time_distribution_rds}

# 


week1 %>% 
  ggplot(aes(x = created_at)) +
    geom_freqpoly(binwidth = 600)

week1 %>% 
  mutate(created_at = ymd_hms(created_at))

week1 %>% 
  mutate(week_day = day(created_at))

week1 %>% 
  

tic("week1_spark_graph")
week1 %>% 
  ggplot(aes(x = created_at)) +
    geom_freqpoly(binwidth = 600) +
    theme_minimal() +
    labs(x = NULL,
         y = "Number of Posts Per Minute",
         title = paste("Variations In Number of Weibo Posts Across A Week"),
         subtitle = paste("Number of Weibo posts between", (week1 %>% arrange(created_at) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")), "and", (week1 %>% arrange(desc(created_at)) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")),"."),
         caption = "HKU WeiboScope Data: King-wa Fu, CH Chan, Michael Chau. Assessing Censorship \non Microblogs in China: Discriminatory Keyword Analysis and Impact Evaluation of the 'Real Name Registration' Policy.\nIEEE Internet Computing. 2013; 17(3): 42-50. http://doi.ieeecomputersociety.org/10.1109/MIC.2013.28")
toc()


tic("week1_graph")
week1_csv %>% 
  ggplot(aes(x = created_at)) +
    geom_freqpoly(binwidth = 600) +
    theme_minimal() +
    labs(x = NULL,
         y = "Number of Posts Per Minute",
         title = paste("Variations In Number of Weibo Posts Across A Week"),
         subtitle = paste("Number of Weibo posts between", (week1 %>% arrange(created_at) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")), "and", (week1 %>% arrange(desc(created_at)) %>% head(1) %>% select(created_at) %>% pull() %>% format(format = "%B %d, %Y")),"."),
         caption = "HKU WeiboScope Data: King-wa Fu, CH Chan, Michael Chau. Assessing Censorship \non Microblogs in China: Discriminatory Keyword Analysis and Impact Evaluation of the 'Real Name Registration' Policy.\nIEEE Internet Computing. 2013; 17(3): 42-50. http://doi.ieeecomputersociety.org/10.1109/MIC.2013.28")
toc()

```

# Spatial Data In China

```{r china_provincial_map}

# We use GADM Global Topolotical dataset to plot out the provincial level map of
# China. However, due to the size of the map (~10M), plotting the original
# simple feature would take too much time. Therefore, we simplify the map while
# preserving its topology using st_simplify.

CHN_simplified <- read_rds("datasets/gadm36_rds/gadm36_CHN_1_sf.rds") %>% 
  st_simplify(preserveTopology = TRUE, dTolerance = 0.01)

# This reduced the size of the map, and makes it more mamagable to print.

object.size(CHN_simplified)

# We print out China's map for testing.

mapview(CHN_simplified)

```

```{r weibo_geo_dist}

WEIBOSCOPE_GEO <- WEIBOSCOPE_ALL %>% 
  
  # We are only concerned about the points that have geo attribute.
  
  filter(!is.na(geo)) %>%
  
  select(geo) %>% 
  
  collect()
  
write_rds(WEIBOSCOPE_GEO, "weibo_air_quality/data/weiboscope_geo_all.rds")

WEIBOSCOPE_GEO

  st_as_sfc(WEIBOSCOPE_GEO$geo, EWKB = TRUE, crs = 4326) %>% 
  
  st_

test <- week1 %>% 
  filter(!is.na(geo))


test_point <- st_as_sfc(test$geo, EWKB = TRUE, crs = 4326)

st_intersection(CHN_simplified, test_point)

st_transform(test_point$geo, 4326)

lengths(st_covers(CHN_simplified, test_point$geo))

mapview(list(CHN_simplified, test_point))

```

# Censorship Frequency

```{r}

permission_denied_dist <- WEIBOSCOPE_ALL %>% 
  filter(!is.na(permission_denied)) %>% 
  mutate(created_date = to_date(created_at)) %>% 
  group_by(created_date) %>% 
  summarize(deleted_count = n()) %>% 
  collect()

write_rds(permission_denied_dist, "weibo_air_quality/data/permission_denied_dist.rds")

permission_denied_dist <- read_rds("weibo_air_quality/data/permission_denied_dist.rds")

censorship_dist_plot <- permission_denied_dist %>% 
  ggplot(aes(x = created_date, y = deleted_count)) +
    geom_line(color = "#d11141") +
    transition_reveal(created_date) +
    theme_minimal() +
    labs(title = "",
         x = NULL,
         y = "Number of Monitored Censored Posts",
         caption = "Source: Open WeiboScope/Hong Kong University") +
    theme(panel.grid.minor = element_blank())

animate(censorship_dist_plot, 
        nframes = 365,
        fps = 30,
        duration = 8,
        end_pause = 150,
        width = 1000,
        height = 500)

anim_save("weibo_air_quality/censorship_dist_plot.gif", animation = censorship_dist_plot,
          nframes = 365,
          fps = 30,
          duration = 10,
          end_pause = 150,
          width = 800,
          height = 400)


permission_denied_all <- WEIBOSCOPE_ALL %>% 
  filter(!is.na(permission_denied)) %>% 
  collect()

write_rds(permission_denied_all, "weibo_air_quality/data/permission_denied_all.rds")


permission_denied_dist


```


# Keyword Frequency

```{r}

keywords <- c("环保", "环境保护", "空气质量", "雾霾", "PM2.5", "霾", "污染", "口罩")

frequency <- tibble(filter_keyword = character(),
                    created_date = date(),
                    post_created = integer())

for (keyword in keywords) {
  WEIBOSCOPE_ALL %>% 
    filter(str_detect(text, keyword)) %>% 
    mutate(created_date = to_date(created_at),
           filter_keyword = keyword) %>% 
    group_by(filter_keyword, created_date) %>% 
    summarize(post_created = n()) %>% 
    collect() %>% 
    bind_rows(frequency) -> frequency
}

write_rds(frequency, "weibo_air_quality/data/keywords_freq_dist.rds")

frequency <- read_rds("weibo_air_quality/data/keywords_freq_dist.rds")

# for (keyword in keywords) {
#   week1 %>% 
#     filter(str_detect(text, keyword)) %>% 
#     mutate(created_date = as_date(created_at),
#            filter_keyword = keyword) %>% 
#     group_by(filter_keyword, created_date) %>% 
#     summarize(post_created = n()) %>% 
#     bind_rows(frequency) -> frequency
# }

frequency %>% 
  mutate(filter_keyword = factor(filter_keyword, 
                                 levels = c("环保", "环境保护", "空气质量", "雾霾", "PM2.5", "霾", "污染", "口罩"),
                                 labels = c("Huan Bao", "Huan Jing Bao Hu", "Kong Qi Zhi Liang",
                                            "Wu Mai", "PM2.5", "Mai", "Wu Ran", "Kou Zhao"))) %>% 
  ggplot(aes(x = created_date, y = post_created, color = filter_keyword)) +
    geom_line()


```

```{r}
library(raster)
library(rasterVis)
library(rgdal)
library(maps)
library(mapdata)
library(maptools)

pm25_1998 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-1998-geotiff/gwr_pm25_1998.tif")
pm25_1999 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-1999-geotiff/gwr_pm25_1999.tif")
pm25_2000 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2000-geotiff/gwr_pm25_2000.tif")
pm25_2001 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2001-geotiff/gwr_pm25_2001.tif")
pm25_2002 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2002-geotiff/gwr_pm25_2002.tif")
pm25_2003 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2003-geotiff/gwr_pm25_2003.tif")
pm25_2004 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2004-geotiff/gwr_pm25_2004.tif")
pm25_2005 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2005-geotiff/gwr_pm25_2005.tif")
pm25_2006 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2006-geotiff/gwr_pm25_2006.tif")
pm25_2007 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2007-geotiff/gwr_pm25_2007.tif")
pm25_2008 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2008-geotiff/gwr_pm25_2008.tif")
pm25_2009 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2009-geotiff/gwr_pm25_2009.tif")
pm25_2010 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2010-geotiff/gwr_pm25_2010.tif")
pm25_2011 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2011-geotiff/gwr_pm25_2011.tif")
pm25_2012 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2012-geotiff/gwr_pm25_2012.tif")
pm25_2013 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2013-geotiff/gwr_pm25_2013.tif")
pm25_2014 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2014-geotiff/gwr_pm25_2014.tif")
pm25_2015 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2015-geotiff/gwr_pm25_2015.tif")
pm25_2016 <- raster("datasets/sdei-pm25/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2016-geotiff/gwr_pm25_2016.tif")

pm25_list <- c("pm25_1998", "pm25_1999", "pm25_2000", "pm25_2001", "pm25_2002", "pm25_2003", "pm25_2004", "pm25_2005", "pm25_2006", "pm25_2007", "pm25_2008", "pm25_2009", "pm25_2010", "pm25_2011", "pm25_2012", "pm25_2013", "pm25_2014", "pm25_2015", "pm25_2016")

# pm25_2012 <- as.data.frame(raster("datasets/sdei-global-annual-gwr-pm2-5-modis-misr-seawifs-aod-2012-geotiff/gwr_pm25_2012.tif"),
#                            xy = TRUE)
# 
# pm25_2012_df <- as.data.frame(pm25_2012, xy = TRUE)
# 
# ggplot(pm25_2012) %>% 
#   geom_tile(aes(fill = factor(gwr_pm25_2012), alpha = 0.8))

# ggplot() +
#     geom_raster(aes(pm25_2012)) +
#     scale_fill_viridis_c() +
#     coord_quickmap()

# plot(pm25_2012)
# 
# pm25_list <- "pm25_1998"
# 
# eval(as.name("pm25_1998"))

# str_split("pm25_1998", pattern = "_")[[1]][2]

colr <- colorRampPalette(rev(brewer.pal(11, 'RdYlBu')))

padding <- list(layout.heights = list(top.padding = 0), 
                layout.widths = list( 
                        left.padding = 0, 
                        right.padding = 0) 
                ) 

for (year in pm25_list) {
  
  png(filename = paste0("weibo_air_quality/pm25_graphs/", year, ".png"), width = 3000, height = 1000,
      res = 300)
  
  plot <- levelplot(
    eval(as.name(year)),
    main = paste("Air Pollution (PM2.5) Concentration in China,", str_split(year, pattern = "_")[[1]][2]),
    xlim = c(70, 140),
    ylim = c(10, 60),
    xlab = NULL,
    ylab = NULL,
    alpha.regions = 0.8,
    maxpixels = 2e6,
    margin = FALSE,
    colorkey = list(
      # space='bottom',                   # plot legend at bottom
      title = "mg / cubic m"
    ),
    # par.settings=list(
    #         axis.line=list(col='transparent') # suppress axes and legend outline
    # ),
    scales=list(draw=FALSE),            # suppress axis labels
    col.regions=colr,                   # colour ramp
    at=seq(0, 110, by = 10),
    par.settings = padding
  ) +
    layer(
      sp.polygons(as_Spatial(CHN_simplified))
    )
  
  print(plot)
  
  dev.off()

}

```

# Economic Graphs

```{r economic_data_proc}

library(janitor)

indicators <- read_csv("datasets/World_Development_Indicators/03d8a56f-acd9-4053-adfd-b596413871f5_Data.csv") %>% 
  clean_names()

unique(indicators$series_name)

selected_indicators <- c("GDP (current US$)", "Poverty headcount ratio at $1.90 a day (2011 PPP) (% of population)", "Urban population (% of total)", "Individuals using the Internet (% of population)", "School enrollment, primary (% gross)", "School enrollment, secondary (% gross)")

cleaned_indicators <- indicators %>% 
  filter(series_name %in% selected_indicators) %>% 
  gather(key = "year", value = "value", x1960_yr1960:x2017_yr2017) %>% 
  select(-country_name, -country_code, -x2018_yr2018, -series_code) %>% 
  mutate(year = map_chr(str_split(year, pattern = "_"), c(1)),
         year = as.integer(str_remove(year, "x")))

write_rds(cleaned_indicators, "weibo_air_quality/data/development_indicators.rds")

china_gdp <- read_csv("datasets/World_Development_Indicators/gdp_dollar.csv",
                               skip = 3) %>% 
  clean_names() %>% 
  filter(country_name == "China") %>% 
  select(-x2018, -x64) %>% 
  gather(key = "year", "value" = gdp, x1960:x2017) %>% 
  mutate(year = as.integer(str_remove(year, "x")))

write_rds(china_gdp, "weibo_air_quality/data/china_gdp.rds")

china_gdp %>% 
  ggplot(aes(x = year, y = gdp)) +
    geom_line() +
    geom_point(size = 0.5) +
    theme_minimal() +
    labs(title = "China's Post-Reform Economy: Rapid Development",
         subtitle = "China's GDP (in current USD) from 1960 to 2017",
         x = NULL) +
    scale_y_continuous(name = "GDP (in trillion dollar)",
                       breaks = seq(0, 14e12, by = 2e12),
                       labels = paste0("$",seq(0, 14, by = 2),"tn")) +
    scale_x_continuous(breaks = seq(1960, 2017, by = 5))

cleaned_indicators %>% 
  filter(series_name == "Urban population (% of total)") %>% 
  mutate(value = as.numeric(value)) %>% 
  ggplot(aes(x = year, y = value)) +
    geom_line() +
    geom_point(size = 0.5) +
    theme_minimal() +
    labs(title = "Into an Urban Society",
         subtitle = "China became predominantly urban in 2011",
         x = NULL) +
    geom_hline(yintercept = 50, linetype="dashed", color = "red") +
    scale_y_continuous(name = "Urban population (% of total)",
                       limits = c(0, 100),
                       breaks = seq(0, 100, by = 10),
                       labels = paste0(seq(0, 100, by = 10),"%")) +
    scale_x_continuous(breaks = seq(1960, 2017, by = 5))


```

